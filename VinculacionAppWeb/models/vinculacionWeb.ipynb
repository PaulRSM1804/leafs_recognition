{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"178b6X4FVf5W-L8FrcVVt8qpdIP-eZ_Io","authorship_tag":"ABX9TyMNw58voJpbcUiIZDWuKfsI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bv1yVRJZrOMw","executionInfo":{"status":"ok","timestamp":1695168873513,"user_tz":300,"elapsed":126223,"user":{"displayName":"PAUL RENATO SALAZAR MENDOZA","userId":"06674112818325930688"}},"outputId":"d01d6006-072f-4c9b-ded5-0a35f06515a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 62 images belonging to 2 classes.\n","Found 52 images belonging to 2 classes.\n","Found 10 images belonging to 2 classes.\n","Epoch 1/30\n","1/1 [==============================] - 6s 6s/step - loss: 0.5931 - accuracy: 1.0000\n","Epoch 2/30\n","1/1 [==============================] - 2s 2s/step - loss: 9.6041e-26 - accuracy: 1.0000\n","Epoch 3/30\n","1/1 [==============================] - 4s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 4/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 5/30\n","1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 6/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 7/30\n","1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 8/30\n","1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 9/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 10/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 11/30\n","1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 12/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 13/30\n","1/1 [==============================] - 4s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 14/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 15/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 16/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 17/30\n","1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 18/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 19/30\n","1/1 [==============================] - 4s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 20/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 21/30\n","1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 22/30\n","1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 23/30\n","1/1 [==============================] - 4s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 24/30\n","1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 25/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 26/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 27/30\n","1/1 [==============================] - 4s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 28/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 29/30\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 30/30\n","1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Accuracy on test data: 1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, regularizers\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Definir las rutas a los directorios de imágenes positivas y negativas\n","positive_dir = '/content/drive/MyDrive/Modelado/positivo'\n","negative_dir = '/content/drive/MyDrive/Modelado/negativo'\n","test_dir = '/content/drive/MyDrive/Modelado/Prueba'\n","\n","# Otras configuraciones, como el tamaño de imagen, batch_size, etc.\n","img_width, img_height = 224, 224  # Ajusta el tamaño de imagen según tus necesidades\n","batch_size = 32  # Ajusta el tamaño de lote según tus necesidades\n","num_epochs = 30\n","\n","# Crear generadores de datos con aumento para entrenamiento y validación.\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n","\n","validation_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Normalización, igual que en entrenamiento y validación\n","    rotation_range=10,  # Rotación más leve\n","    width_shift_range=0.1,  # Cambio de ancho menor\n","    height_shift_range=0.1,  # Cambio de alto menor\n","    shear_range=0.1,  # Menor efecto de deformación\n","    zoom_range=0.1,  # Menor rango de zoom\n","    horizontal_flip=False,  # Desactivar volteo horizontal\n","    fill_mode='nearest')  # Usar el método de relleno más cercano)\n","\n","# Crear un generador de datos de flujo desde el directorio de prueba\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,  # Usar el directorio de imágenes de prueba\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='binary',  # Usar class_mode='binary' para dos clases (positivo y negativo)\n","    interpolation='nearest',  # Puedes cambiar la interpolación según tus necesidades\n","    shuffle=False,  # Desactiva la aleatorización de datos para que los resultados sean coherentes\n","    classes=['positivo', 'negativo'])  # Especificar explícitamente los nombres de las clases\n","\n","# Crear generadores de datos de flujo desde directorios para entrenamiento y validación\n","train_generator = train_datagen.flow_from_directory(\n","    positive_dir,  # Usar el directorio de imágenes positivas\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='binary',  # Usar class_mode='binary' para dos clases (positivo y negativo)\n","    interpolation='nearest',  # Puedes cambiar la interpolación según tus necesidades\n","    subset='training',  # Agregar esta línea para especificar que es el conjunto de entrenamiento\n","    classes=['class_positivo', 'class_negativo'])  # Especificar explícitamente los nombres de las clases\n","\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    negative_dir,  # Usar el directorio de imágenes negativas\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='binary',  # Usar class_mode='binary' para dos clases (positivo y negativo)\n","    interpolation='nearest',  # Puedes cambiar la interpolación según tus necesidades\n","    shuffle=False,  # Desactivar la aleatorización de datos para que los resultados sean coherentes\n",")\n","\n","\n","\n","\n","# Definir el modelo CNN con regularización Dropout\n","model = keras.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dropout(0.5),  # Agregar regularización Dropout\n","    layers.Dense(512, activation='relu'),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compilar el modelo\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Entrenar el modelo\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // batch_size,  # Número de pasos por época\n","    epochs=num_epochs,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // batch_size)  # Número de pasos de validación\n","\n","# Evaluar el modelo en el conjunto de prueba (debes cargar los datos de prueba de manera similar a los datos de entrenamiento y validación)\n","test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n","print(f'Accuracy on test data: {test_acc}')\n","\n","# Guardar el modelo entrenado para su posterior uso\n","model.save('spectral_banana_detection_model.h5')\n"]},{"cell_type":"code","source":[],"metadata":{"id":"d65-axb7sSE4"},"execution_count":null,"outputs":[]}]}